# Optimizaci√≥n de Hiperpar√°metros - Versi√≥n Argentina

Gu√≠a para optimizar los hiperpar√°metros del modelo de predicci√≥n de floods.

## üìã Resumen

Este proceso permite mejorar el rendimiento del modelo ajustando los hiperpar√°metros mediante b√∫squeda automatizada.

## üîÑ Modelos de Respaldo

**IMPORTANTE**: Antes de optimizar, se crea autom√°ticamente un respaldo:
- `flood_predictor_argentina_base.pkl` - Modelo original (respaldo)
- `flood_predictor_argentina.pkl` - Modelo actual (se actualiza despu√©s de optimizar)
- `flood_predictor_argentina_optimizado.pkl` - Modelo optimizado

## üöÄ Opciones de Optimizaci√≥n

### Opci√≥n 1: Optimizaci√≥n R√°pida (Recomendada)

Optimiza solo XGBoost (el mejor modelo) con b√∫squeda r√°pida.

```bash
cd version_argentina
python optimizar_hiperparametros_rapido.py
```

**Caracter√≠sticas:**
- ‚è±Ô∏è Tiempo: 5-10 minutos
- üéØ Enfoque: Solo XGBoost (mejor modelo)
- üìä Iteraciones: 25 combinaciones
- ‚úÖ Ideal para: Mejoras r√°pidas

### Opci√≥n 2: Optimizaci√≥n Completa

Optimiza todos los modelos (XGBoost, Random Forest, Gradient Boosting) con b√∫squeda exhaustiva.

```bash
cd version_argentina
python optimizar_hiperparametros.py
```

**Caracter√≠sticas:**
- ‚è±Ô∏è Tiempo: 30-60 minutos
- üéØ Enfoque: Todos los modelos
- üìä Iteraciones: 50-30 combinaciones por modelo
- ‚úÖ Ideal para: M√°xima optimizaci√≥n

## üìä Qu√© se Optimiza

### XGBoost
- `n_estimators`: N√∫mero de √°rboles (150-300)
- `max_depth`: Profundidad m√°xima (5-8)
- `learning_rate`: Tasa de aprendizaje (0.05-0.15)
- `subsample`: Fracci√≥n de muestras (0.85-0.95)
- `colsample_bytree`: Fracci√≥n de features (0.85-0.95)
- `min_child_weight`: Peso m√≠nimo por hoja (1-3)
- `gamma`: Reducci√≥n m√≠nima de p√©rdida (0-0.1)
- `reg_alpha`: Regularizaci√≥n L1 (0-0.1)
- `reg_lambda`: Regularizaci√≥n L2 (1-1.5)

### Random Forest
- `n_estimators`: N√∫mero de √°rboles (100-300)
- `max_depth`: Profundidad m√°xima (10-18)
- `min_samples_split`: M√≠nimo para dividir (2-10)
- `min_samples_leaf`: M√≠nimo por hoja (1-5)
- `max_features`: Features por split
- `bootstrap`: Muestreo con reemplazo

### Gradient Boosting
- `n_estimators`: N√∫mero de √°rboles (100-300)
- `max_depth`: Profundidad m√°xima (3-9)
- `learning_rate`: Tasa de aprendizaje (0.01-0.2)
- `subsample`: Fracci√≥n de muestras (0.8-1.0)
- `min_samples_split`: M√≠nimo para dividir (2-10)
- `min_samples_leaf`: M√≠nimo por hoja (1-4)

## üìà M√©tricas de Evaluaci√≥n

La optimizaci√≥n busca maximizar el **F1-Score** usando validaci√≥n cruzada temporal (TimeSeriesSplit).

Despu√©s de optimizar, se eval√∫an:
- **F1-Score**: Balance entre precisi√≥n y recall
- **Precision**: Exactitud de predicciones positivas
- **Recall**: Capacidad de detectar floods reales
- **AUC-ROC**: Capacidad discriminativa
- **Average Precision**: Rendimiento en Precision-Recall

## üîç Comparaci√≥n con Modelo Base

Despu√©s de optimizar, el script muestra una comparaci√≥n:

```
M√©trica              Base            Optimizado      Mejora
------------------------------------------------------------
F1-Score            0.6587          0.6750          +0.0163
Precision           0.6710          0.6820          +0.0110
Recall              0.6468          0.6680          +0.0212
AUC-ROC             0.9435          0.9450          +0.0015
```

## ‚öôÔ∏è Proceso de Optimizaci√≥n

1. **Carga de datos**: Se cargan los datos procesados
2. **Preparaci√≥n**: Se recrean las features y el target
3. **B√∫squeda**: RandomizedSearchCV prueba combinaciones aleatorias
4. **Validaci√≥n**: TimeSeriesSplit respeta el orden temporal
5. **Evaluaci√≥n**: Se eval√∫a en conjunto de test
6. **Guardado**: Se guarda el modelo optimizado

## üìù Salida del Script

El script muestra:
- Progreso de la b√∫squeda
- Mejores par√°metros encontrados
- M√©tricas en validaci√≥n cruzada
- M√©tricas en conjunto de test
- Comparaci√≥n con modelo base
- Archivos generados

## üîß Personalizaci√≥n

Si quieres ajustar la b√∫squeda, edita los archivos:

### Para optimizaci√≥n r√°pida:
- `optimizar_hiperparametros_rapido.py`
- Modifica `n_iter` para m√°s/menos iteraciones
- Modifica `param_grid` para cambiar rangos

### Para optimizaci√≥n completa:
- `optimizar_hiperparametros.py`
- Modifica `n_iter` por modelo
- Ajusta `param_grid` de cada modelo

## ‚ö†Ô∏è Notas Importantes

1. **Tiempo de ejecuci√≥n**: La optimizaci√≥n puede tardar varios minutos
2. **Recursos**: Usa todos los cores disponibles (n_jobs=-1)
3. **Respaldo**: El modelo base se guarda autom√°ticamente
4. **Validaci√≥n temporal**: Se usa TimeSeriesSplit para respetar orden temporal
5. **Balanceo**: Se aplica SMOTE si est√° disponible

## üÜò Soluci√≥n de Problemas

### Error: "No se encuentra el modelo base"
- Aseg√∫rate de que existe `flood_predictor_argentina_base.pkl`
- Si no existe, el script usar√° valores por defecto

### Error: "Memoria insuficiente"
- Reduce `n_iter` en el script
- Reduce el tama√±o del conjunto de entrenamiento

### Optimizaci√≥n muy lenta
- Usa `optimizar_hiperparametros_rapido.py` en lugar del completo
- Reduce `n_iter` y el rango de par√°metros

## üìä Resultados Esperados

Despu√©s de optimizar, puedes esperar mejoras de:
- **F1-Score**: +1-5% t√≠picamente
- **Precision**: +1-3% t√≠picamente
- **Recall**: +1-3% t√≠picamente
- **AUC-ROC**: +0.1-0.5% t√≠picamente (ya es muy alto)

## üîÑ Volver al Modelo Base

Si quieres volver al modelo original:

```bash
cd version_argentina
Copy-Item flood_predictor_argentina_base.pkl flood_predictor_argentina.pkl
```

## üìö Pr√≥ximos Pasos

Despu√©s de optimizar:
1. Ejecuta `evaluar_modelo_entrenado.py` para ver m√©tricas detalladas
2. Ejecuta `generar_graficas_evaluacion.py` para generar gr√°ficas actualizadas
3. Compara resultados con el modelo base

## üí° Consejos

- **Primera vez**: Usa optimizaci√≥n r√°pida para ver mejoras
- **M√°xima calidad**: Usa optimizaci√≥n completa si tienes tiempo
- **Iterativo**: Puedes ejecutar m√∫ltiples veces ajustando rangos
- **Monitoreo**: Revisa las m√©tricas en cada ejecuci√≥n









